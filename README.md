# Querido DiÃ¡rio Workers

Serverless crawler for Brazilian official gazettes (diÃ¡rios oficiais) using **Cloudflare Workers** and **Queues**.

This is a TypeScript/Node.js port of the [querido-diario](https://github.com/okfn-brasil/querido-diario) project, redesigned for serverless architecture.

## Features

- âœ… **Serverless**: Runs on Cloudflare Workers (no servers to manage)
- âœ… **Scalable**: Uses Cloudflare Queues for distributed crawling
- âœ… **TypeScript**: Fully typed codebase
- âœ… **1,937 Cities**: 17 platform types implemented (**28.2% national coverage**)
- âœ… **Lightweight**: Extracts gazette metadata and PDF URLs (no file downloads)
- âœ… **Fast**: Average 400-500ms per city crawl

## ğŸ“Š National Coverage

**1,573 of 5,570 Brazilian municipalities (28.24%)**

### Coverage by State

| UF | Total | Covered | Coverage | Progress |
|----|-------|---------|----------|----------|
| **MT** | 141 | 139 | **98.6%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘` |
| **PE** | 185 | 182 | **98.4%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘` |
| **RN** | 167 | 160 | **95.8%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘` |
| **CE** | 184 | 127 | **69.0%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| **MG** | 853 | 474 | **55.6%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| **RS** | 497 | 262 | **52.7%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| **PR** | 399 | 176 | **44.1%** | `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| **PI** | 224 | 31 | **13.8%** | `â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| **PB** | 223 | 22 | **9.9%** | `â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |
| Other states | 2,897 | 0 | 0.0% | `â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |

*Last updated: 2025-10-04*

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cloudflare Infrastructure                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  HTTP Request â†’ Dispatcher Worker â†’ Queue â†’ Consumer Worker â”‚
â”‚                                                               â”‚
â”‚  1. POST /crawl with city list                              â”‚
â”‚  2. Enqueue tasks to Cloudflare Queue                       â”‚
â”‚  3. Consumer workers process each city                       â”‚
â”‚  4. Return gazette metadata + PDF URLs                       â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
querido-diario-workers/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                  # Dispatcher worker
â”‚   â”œâ”€â”€ consumer.ts               # Queue consumer worker
â”‚   â”œâ”€â”€ types/                    # TypeScript interfaces
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ base/                 # Base spider classes
â”‚   â”‚   â”‚   â”œâ”€â”€ base-spider.ts
â”‚   â”‚   â”‚   â””â”€â”€ doem-spider.ts
â”‚   â”‚   â”œâ”€â”€ configs/              # Spider configurations
â”‚   â”‚   â”‚   â””â”€â”€ doem-cities.json
â”‚   â”‚   â””â”€â”€ registry.ts           # Spider factory
â”‚   â””â”€â”€ utils/                    # Utilities (HTTP, parsing, dates, logging)
â”œâ”€â”€ wrangler.jsonc                # Dispatcher configuration
â”œâ”€â”€ wrangler.consumer.jsonc       # Consumer configuration
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Getting Started

### Prerequisites

- Node.js 18+
- npm or pnpm
- Cloudflare account (for deployment)

### Installation

```bash
npm install
```

### Development

Run the unified worker locally:

```bash
npm run dev
```

### Deployment

Deploy the unified worker:

```bash
npm run deploy
```

## API Usage

### Start a Crawl

**POST** `/crawl`

```json
{
  "cities": ["ba_acajutiba", "ba_alagoinhas"],
  "startDate": "2024-01-01",
  "endDate": "2024-12-31"
}
```

**Response:**

```json
{
  "success": true,
  "tasksEnqueued": 2,
  "cities": ["ba_acajutiba", "ba_alagoinhas"]
}
```

### List Available Spiders

**GET** `/spiders`

```json
{
  "total": 50,
  "spiders": [
    {
      "id": "ba_acajutiba",
      "name": "Acajutiba - BA",
      "territoryId": "2900306",
      "type": "doem",
      "startDate": "2013-01-30"
    }
  ]
}
```

### Filter by Type

**GET** `/spiders?type=doem`

## Supported Platforms

### Current

- **DOEM** (DiÃ¡rio Oficial EletrÃ´nico dos MunicÃ­pios): **56 cities** âœ…
  - 52 cities in Bahia (BA)
  - 1 city in Pernambuco (PE)
  - 2 cities in ParanÃ¡ (PR)
  - 1 city in Sergipe (SE)

## Supported Platforms

| Platform | Cities | Status |
|----------|--------|--------|
| **SIGPub** | 1,573 | âœ… |
| **Instar** | 111 | âœ… |
| **DOEM** | 56 | âœ… |
| **DOSP** | 42 | âœ… |
| **ADiarios V1** | 34 | âœ… |
| **MunicipioOnline** | 26 | âœ… |
| **AtendeV2** | 22 | âœ… |
| **DIOF** | 20 | âœ… |
| **DiarioOficialBR** | 10 | âœ… |
| **Siganet** | 10 | âœ… |
| **Modernizacao** | 7 | âœ… |
| **BarcoDigital** | 7 | âœ… |
| **ADiarios V2** | 5 | âš ï¸ Stub |
| **Aplus** | 4 | âœ… |
| **Dioenet** | 4 | âœ… |
| **AdministracaoPublica** | 3 | âœ… |
| **PTIO** | 3 | âœ… |
| **Total** | **1,937** | **28.2%** |

### Planned

- Other platforms: ~158 cities remaining

## Output Format

Each crawl returns gazette metadata:

```json
{
  "spiderId": "ba_acajutiba",
  "territoryId": "2900306",
  "gazettes": [
    {
      "date": "2024-01-15",
      "editionNumber": "1234",
      "fileUrl": "https://doem.org.br/ba/acajutiba/diarios/...",
      "isExtraEdition": false,
      "power": "executive_legislative",
      "territoryId": "2900306",
      "scrapedAt": "2024-10-03T16:30:00.000Z"
    }
  ],
  "stats": {
    "totalFound": 1,
    "dateRange": {
      "start": "2024-01-01",
      "end": "2024-12-31"
    },
    "requestCount": 12,
    "executionTimeMs": 3450
  }
}
```

## Development Roadmap

- [x] Core infrastructure (types, utils, base classes)
- [x] DOEM spider implementation (56 cities) âœ…
- [x] Unified worker (dispatcher + consumer)
- [x] Instar spider (111 cities) âœ…
- [x] DOSP spider (42 cities) âœ…
- [x] ADiarios V1 spider (34 cities) âœ…
- [x] DIOF spider (20 cities) âœ…
- [x] BarcoDigital spider (7 cities) âœ…
- [x] Siganet spider (10 cities) âœ…
- [x] DiarioOficialBR spider (10 cities) âœ…
- [x] Modernizacao spider (7 cities) âœ…
- [x] Aplus spider (4 cities) âœ…
- [x] Dioenet spider (4 cities) âœ…
- [x] AdministracaoPublica spider (3 cities) âœ…
- [x] PTIO spider (3 cities) âœ…
- [ ] ADiarios V2 spider (5 cities) - requires browser automation
- [ ] Remaining platforms (~158 cities)
- [ ] Storage integration (D1/KV/R2)
- [ ] Monitoring and alerting
- [ ] PDF download worker (optional)

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## License

MIT License

## Acknowledgments

Based on the original [Querido DiÃ¡rio](https://github.com/okfn-brasil/querido-diario) project by [Open Knowledge Brasil](https://ok.org.br/).

## Related Projects

- [querido-diario](https://github.com/okfn-brasil/querido-diario) - Original Python/Scrapy implementation
- [Querido DiÃ¡rio Website](https://queridodiario.ok.org.br/) - Official project website
